%% load the normative deviations (referred to as Z as they are z-scored)
load('precentral_inclusion.mat', 'Zs' , 'Zeids', 'headers')
%% select only the subjects who meet inclusion criteria
load('include.mat')
new_eids = intersect(include, subs);
[~, include_idx] = intersect(Zeids, new_eids);
Zs = Zs(include_idx, :);
Zeids = Zeids(include_idx, :);
%% load the ids for each group
anhedonia_eid = table2array(readtable('anhedonia.csv'));
lowmood_eid = table2array(readtable('lowmood.csv'));
somatic_eid = table2array(readtable('somatic.csv'));
chronic_eid = table2array(readtable('chronic.csv'));
lateonset_eid = table2array(readtable('lateonset.csv'));
acuteimpair_eid = table2array(readtable('acuteimpairment.csv'));
heterogeneous_eid = table2array(readtable('heterogeneousComparison.csv'));

%get the intersection of the complete eid list and eid list for the
%specific group. This also creates a cell array of the subgroup ids
[groups{1}, ia] = intersect(Zeids(:,1), anhedonia_eid(:,1)); Z{1} = Zs(ia, :);
[groups{2}, im] = intersect(Zeids(:,1), mood_eid(:,1)); Z{2} = Zs(im, :);
[groups{3}, is] = intersect(Zeids(:,1), somatic_eid(:,1)); Z{3} = Zs(is, :);
[groups{4}, ic] = intersect(Zeids(:,1), chronic_eid(:,1)); Z{4} = Zs(ic, :);
[groups{5}, il] = intersect(Zeids(:,1), lateonset_eid(:,1)); Z{5} = Zs(il, :);
[groups{6}, ise] = intersect(Zeids(:,1), acuteimpair_eid(:,1)); Z{6} = Zs(ise, :);
[~, ih] = intersect(Zeids(:,1), heterogeneous_eid(:,1)); Z{7} = Zs(ih, :);
%% aim 1 anova
% create an array that provides the group number for each subject
G(ia, 1) = 1;
G(im, 1) = 2;
G(is, 1) = 3;
G(ic, 1) = 4;
G(il, 1) = 5;
G(ise, 1) = 6;
G(ih, 1) = 7;
for n = 1:size(Zs,2)
    [anovaPs(n), tbl{n}, stats{n}] = anovan(Zs(:,n),G,'display','off');
    fstat_true(n) = cell2mat(tbl{n}(2,6)); %this will be used for a supplemental analysis
end
save('fstat_true.mat', 'fstat_true')
[p_fdr] = mafdr(anovaPs); %%False Discovery Rate correction
sigidx = find(p_fdr < 0.05); %% index for significant Zs

% determine the significant post hoc comparisons
for i = 1:length(sigidx)
 c{i} = multcompare(stats{sigidx(i)});
 h{i}= find(c{i}(:,6) < 0.0500);
end
for i = 1:length(sigidx)
   sig_groups_posthoc{i} = c{i}(h{i}, 1:2);
   sig_ps{i} = c{i}(h{i},6);
end
%% aim 2 data driven clustering
for i = 1:1000 %number of bootstraps
    for n = 1:6 %number of clinically dissociated groups
        ix = randi(length(Z{n}), [length(Z{n}),1]);
        data = Z{n}(ix,:);
        [~, score, ~, ~, explained]= pca(Z{n});
        esum = zeros(size(Z{n},2),1);
        esum(1) = explained(1);
        for b = 2:size(Z{n},2)
            esum(b) = esum(b-1) + explained(b);
        end
        f = find(esum > 75); %select the number of PCs that explain 75% variance
        fs(i) = f(1,1);
        [~, ka(i,n)] = clusk(score(:,1:f(1,1)), 10); %kmeans clustering, output is best k for the bootstrap
        i
    end
end
%%find optimal cluster number
for i = 1:6
    cluster(i) = mode(ka(:,i));
end

% final kmeans solutions
for n = 1:6
     [~, score_final{n}, ~, ~, explained]= pca(Z{n});
        esum = zeros(size(Z{n},2),1);
        esum(1) = explained(1);
        for b = 2:size(Z{n},2)
            esum(b) = esum(b-1) + explained(b);
        end
        f = find(esum > 75);
        fs(i) = f(1,1);
        [kms_final{n}] = kmeans(score_final{n}(:,1:f(1,1)), cluster(n)); 
end
%% cross validation to determine cluster stability
% split into test and training
folds = 10; %number of cross validation folds
for x = 1:100 %repeated 100 times
    for i = 1:folds
        for n = 1:6
            c = cvpartition(size(Z{n},1),'KFold',folds);
            idxTrain{x,i,n} = training(c, i);
            Z_Train{x,i, n} = Z{n}(idxTrain{x,i,n},:);
            idxNew{x,i,n} = test(c, i);
            Z_New{x,i, n} = Z{n}(idxNew{x,i,n},:);
        end
    end

    for i = 1:folds
        for n = 1:6
            [coeff{x,i,n}, score_temp{x,i,n}, ~,~,explained] = pca(Z_Train{x, i, n}); %%I think I need to save out the weights of this PCA to use 2 steps down
            esum = zeros(size(Z{n},2),1);
            esum(1) = explained(1);
            for b = 2:size(Z{n},2)
                esum(b) = esum(b-1) + explained(b);
            end
            f = find(esum > 75);
            [kms_temp{x,i,n}, centroid{x,i,n}] = kmeans(score_temp{x,i,n}(:,1:f(1,1)), cluster(n)); 
            score = Z_New{x,i, n}*coeff{x,i,n}; %apply PCA loadings to heldout set
            score_new{x,i,n} = score(:,1:f(1,1));
        end
    end
    
    for i = 1:folds
        for n=1:6
            for j = 1:size(centroid{x,i,n}, 1)
                for k = 1:size(score_new{x,i,n},1)
                    A{x,i,n}{j,k} = sum((centroid{x,i,n}(j,:)-score_new{x,i,n}(k,:)).^2,2); %determine cluster assignment for heldout data
                    [~,cl_idx{x,i,n}(k)] = min(cell2mat(A{x,i,n}(:,k)));
                end
            end
            total{x,i, n} = zeros(1,length(idxTrain{x,i,n}));
            total{x,i, n}(:,idxTrain{x,i,n}) = kms_temp{x,i,n};
            total{x,i, n}(:,idxNew{x,i,n}) = cl_idx{x,i,n};     
        end
    end
end

%%%calculate ARI (adjusted rand index) for folds
 for n = 1:6
    for x = 1:100
        for i = 1:folds
            for j = i+1:folds
                ARI_val(i,j) = rand_index(total{x,i,n},total{x,j,n}, 'adjusted'); %https://www.mathworks.com/matlabcentral/fileexchange/49908-adjusted-rand-index
                ARI_all{n,x}(i,j) = ARI_val(i,j);

            end  
        end
        ARI_val100 = mean(ARI_val(find(~tril(ones(size(ARI_val))))));
    end
    ARI_dist{n} = mean(ARI_val100);
    n
 end
%% cluster validation of phenotype: cognitive ability
D = readtable('Cognition.tsv','FileType','text');
D = standardizeMissing(D,-3); D = standardizeMissing(D,-1); D = standardizeMissing(D,-818); D = standardizeMissing(D,-121); D = standardizeMissing(D,-7);
Reasoning = [D.x20016_0_0];
ReactionTime = [D.x20023_0_0];
COG = [D.eid 0.768*Reasoning + -0.768*log(ReactionTime)]; %as determined in Lyall et al 2016
clear D Reasoning ReactionTime

%%%%%%%%%% select the cog data for each clinically dissociated group
[~, ia] = intersect(COG(:,1), groups{1}(:,1)); cogs{1} = COG(ia, 2); 
[~, im] = intersect(COG(:,1), groups{2}(:,1)); cogs{2} = COG(im, 2);
[~, is] = intersect(COG(:,1), groups{3}(:,1)); cogs{3} = COG(is, 2);
[~, ic] = intersect(COG(:,1), groups{4}(:,1)); cogs{4} = COG(ic, 2);
[~, il] = intersect(COG(:,1), groups{5}(:,1)); cogs{5} = COG(il, 2);
[~, ise] = intersect(COG(:,1), groups{6}(:,1)); cogs{6} = COG(ise, 2);

%remove the missing data
for n = 1:6
    nans{n} = isnan(cogs{n}); 
end
for n = 1:6
    cog_nanless{n} = cogs{n}(~any(nans{n},2),:);
    kms_cog{n} = kms_final{n}(~any(nans{n},2),:); %remove the 
end

%%run ttest
for i=1:6
        [~, p_cogs_6(i), ci, stats] = ttest2(cog_nanless{i}(kms_cog{i}==1), cog_nanless{i}(kms_cog{i}==2)); %this is exactly a ttest, I just did it this way cause I didn't want to restructure my data. To calculate t stat from F stat, t2 = F
tstat_cog(i) = stats.tstat;
end
[~,pcor_cog] = fdr(p_cogs_6); %%%% fdr.m by Anderson M. Winkler 
clear COG cog_nanless kms_cog
%% cog - reasoning or reactiontime
cog_dir = '/Users/kayla/boxdrive/ThesisLab_April2021/ThesisProjectCode/Data/';
D = readtable([cog_dir 'Cognition.tsv'],'FileType','text');
D = standardizeMissing(D,-3); D = standardizeMissing(D,-1); D = standardizeMissing(D,-818); D = standardizeMissing(D,-121); D = standardizeMissing(D,-7);
Reasoning = [D.x20016_0_0];
ReactionTime = [D.x20023_0_0];

%%%%%%%%%% create new group_eid for new subjects
[~, ia] = intersect(D.eid, groups{1}); Reason{1} = Reasoning(ia, 1);
[~, im] = intersect(D.eid, groups{2}); Reason{2} = Reasoning(im, 1);
[~, is] = intersect(D.eid, groups{3}); Reason{3} = Reasoning(is, 1);
[~, ic] = intersect(D.eid, groups{4}); Reason{4} = Reasoning(ic, 1);
[~, il] = intersect(D.eid, groups{5}); Reason{5} = Reasoning(il, 1);
[~, ise] = intersect(D.eid, groups{6}); Reason{6} = Reasoning(ise, 1);

for n = 1:6
    nans{n} = isnan(Reason{n});
end
for n = 1:6
    Reason_nanless{n} = Reason{n}(~any(nans{n},2),:);
    kms_Reason{n} = kms_final{n}(~any(nans{n},2),:);
end
%%run ttest
for i=1:6
        [~, p_Reason_6(i), ~, stat] = ttest2(Reason_nanless{i}(kms_Reason{i}==1), Reason_nanless{i}(kms_Reason{i}==2)); %this is exactly a ttest, I just did it this way cause I didn't want to restructure my data. To calculate t stat from F stat, t2 = F
tstat_Reason(i) = stat.tstat;
end
clear Reason Reason_nanless kms_Reason Reasoning

[~, ia] = intersect(D.eid, groups{1}); React{1} = ReactionTime(ia, 1);
[~, im] = intersect(D.eid, groups{2}); React{2} = ReactionTime(im, 1);
[~, is] = intersect(D.eid, groups{3}); React{3} = ReactionTime(is, 1);
[~, ic] = intersect(D.eid, groups{4}); React{4} = ReactionTime(ic, 1);
[~, il] = intersect(D.eid, groups{5}); React{5} = ReactionTime(il, 1);
[~, ise] = intersect(D.eid, groups{6}); React{6} = ReactionTime(ise, 1);
clear D

for n = 1:6
    nans{n} = isnan(React{n});
end
for n = 1:6
    React_nanless{n} = React{n}(~any(nans{n},2),:);
    kms_React{n} = kms_final{n}(~any(nans{n},2),:);
end
%%run ttest
for i=1:6
        [~, p_React_6(i)] = ttest2(React_nanless{i}(kms_React{i}==1), React_nanless{i}(kms_React{i}==2)); %this is exactly a ttest, I just did it this way cause I didn't want to restructure my data. To calculate t stat from F stat, t2 = F
end
clear ReactionTime React React_nanless kms_React

[~,pcor_Reason] = fdr(p_Reason_6);
[~,pcor_React] = fdr(p_React_6);
%% N
D = readtable([cog_dir 'kayla.tsv'],'FileType','text');
D = standardizeMissing(D,-3); D = standardizeMissing(D,-1); D = standardizeMissing(D,-818); D = standardizeMissing(D,-121); D = standardizeMissing(D,-7);
N12 = sum([D.x1920_0_0, D.x1930_0_0, D.x1940_0_0, D.x1950_0_0, D.x1960_0_0, D.x1970_0_0, D.x1980_0_0, D.x1990_0_0, D.x2000_0_0, D.x2010_0_0, D.x2020_0_0, D.x2030_0_0], 2);

[~, ia] = intersect(D.eid, groups{1}(:,1)); N{1} = N12(ia, :);
[~, im] = intersect(D.eid, groups{2}(:,1)); N{2} = N12(im, :);
[~, is] = intersect(D.eid, groups{3}(:,1)); N{3} = N12(is, :);
[~, ic] = intersect(D.eid, groups{4}(:,1)); N{4} = N12(ic, :);
[~, il] = intersect(D.eid, groups{5}(:,1)); N{5} = N12(il, :);
[~, ise] = intersect(D.eid, groups{6}(:,1)); N{6} = N12(ise, :);
%remove missing data
for n = 1:6
    nans{n} = isnan(N{n});
end
for n = 1:6
    N_nanless{n} = N{n}(~any(nans{n},2),:);
    N_zscore{n} = zscore(N_nanless{n});
    kms_N{n} = kms_final{n}(~any(nans{n},2),:);
end
%run ttest
% for i=1:6
%         [p_N_6(i), ~, stats] = ranksum(N_zscore{i}(kms_N{i}==1), N_zscore{i}(kms_N{i}==2)); %this is exactly a ttest, I just did it this way cause I didn't want to restructure my data. To calculate t stat from F stat, t2 = F
% tstat_N(i) = stats.tstat;
% end
for i=1:6
        [~, pR_N_6(i), ~, stats] = ttest2(N_zscore{i}(kms_N{i}==1), N_zscore{i}(kms_N{i}==2)); %this is exactly a ttest, I just did it this way cause I didn't want to restructure my data. To calculate t stat from F stat, t2 = F
tstat_N(i) = stats.tstat;
end
[~,pcor_N] = fdr(p_N_6); %%%% fdr.m by Anderson M. Winkler 
clear D N12 N N_nanless N_zscore kms_N
%% Townsend
D = readtable([cog_dir 'kayla.tsv'],'FileType','text');
D = standardizeMissing(D,-3); D = standardizeMissing(D,-1); D = standardizeMissing(D,-818); D = standardizeMissing(D,-121); D = standardizeMissing(D,-7);

[~, ia] = intersect(D.eid, groups{1}(:,1)); T{1} = D.x189_0_0(ia, :);
[~, im] = intersect(D.eid, groups{2}(:,1)); T{2} = D.x189_0_0(im, :);
[~, is] = intersect(D.eid, groups{3}(:,1)); T{3} = D.x189_0_0(is, :);
[~, ic] = intersect(D.eid, groups{4}(:,1)); T{4} = D.x189_0_0(ic, :);
[~, il] = intersect(D.eid, groups{5}(:,1)); T{5} = D.x189_0_0(il, :);
[~, ise] = intersect(D.eid, groups{6}(:,1)); T{6} = D.x189_0_0(ise, :);
%remove missing data
for n = 1:6
    nans{n} = isnan(T{n});
end
for n = 1:6
    T_nanless{n} = T{n}(~any(nans{n},2),:);
    T_zscore{n} = zscore(T_nanless{n});
    kms_T{n} = kms_final{n}(~any(nans{n},2),:);
end
%run ttest
for i=1:6
        [~, p_T_6(i), ~, stats] = ttest2(T_zscore{i}(kms_T{i}==1), T_zscore{i}(kms_T{i}==2)); %this is exactly a ttest, I just did it this way cause I didn't want to restructure my data. To calculate t stat from F stat, t2 = F
tstat_T(i) = stats.tstat;
end
[~,pcor_T] = fdr(p_T_6);
clear D T T_nanless T_zscore kms_T
% save('pcor_T_PCA.mat', 'pcor_T_PCA')
%% C-reactive protein = 30710 (not used)
%%%%%%% NEED TO FIND WHERE CRP IS STORED 
D = readtable('/Users/kayla/boxdrive/ThesisLab_April2021/ThesisProjectCode/Data/allage/Subgroups.tsv','FileType','text');
D = standardizeMissing(D,-3); D = standardizeMissing(D,-1); D = standardizeMissing(D,-818); D = standardizeMissing(D,-121); D = standardizeMissing(D,-7);

[~, ia] = intersect(D.eid, groups{1}(:,1)); CRP{1} = D.x30710_0_0(ia, :);
[~, im] = intersect(D.eid, groups{2}(:,1)); CRP{2} = D.x30710_0_0(im, :);
[~, is] = intersect(D.eid, groups{3}(:,1)); CRP{3} = D.x30710_0_0(is, :);
[~, ic] = intersect(D.eid, groups{4}(:,1)); CRP{4} = D.x30710_0_0(ic, :);
[~, il] = intersect(D.eid, groups{5}(:,1)); CRP{5} = D.x30710_0_0(il, :);
[~, ise] = intersect(D.eid, groups{6}(:,1)); CRP{6} = D.x30710_0_0(ise, :);
%remove missing data
for n = 1:6
    nans{n} = isnan(CRP{n});
end
for n = 1:6
    CRP_nanless{n} = CRP{n}(~any(nans{n},2),:);
    kms_CRP{n} = kms_final{n}(~any(nans{n},2),:);
end
%run anova
for i=1:6
        [~, p_CRP_6(i)] = ttest2(CRP_nanless{i}(kms_CRP{i}==1), CRP_nanless{i}(kms_CRP{i}==2));
end
for i=1:6
        [pR_CRP_6(i)] = ranksum(CRP_nanless{i}(kms_CRP{i}==1), CRP_nanless{i}(kms_CRP{i}==2));
end
[~,pcor_CRP] = fdr(p_CRP_6);
%% Functions
function [idx_kms, a] = clusk(Z, varargin)
for n = 1:varargin{1}
    kms(:,n) = kmeans(Z, n);
    kms_sil(:,n) = mean(silhouette(Z, kms(:,n)));
end
[~, a] = max(kms_sil);
idx_kms = kms(:,a);
end